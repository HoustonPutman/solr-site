Title: Quick Start

<ul class="breadcrumbs">
  <li><a href="/solr">Home</a></li>
  <li><a href="/solr/resources.html">Resources</a></li>
</ul>

# Solr Quick Start

***

## Overview

This document covers getting Solr up and running, ingesting a variety of data sources into multiple collections, and getting a feel
for the Solr administrative and search interfaces.

***

## Requirements

To follow along with this tutorial, you will need...

1. Java 1.7 or greater. Some places you can get it are from Oracle or Open JDK.
    * Running java -version at the command line should indicate a version number starting with 1.7.
    * Gnu's GCJ is not supported and does not work with Solr.
2. An Apache Solr release.  This Quick Start was written using Apache Solr 4.10.2.  Some fiddly details will be different/clunkier for earlier versions and more streamlined in later versions.
    
***

## Getting Started

Please run the browser showing this tutorial and the Solr server on the same machine so tutorial links will correctly point to your Solr server.

Begin by unzipping the Solr release and changing your working directory to the subdirectory where Solr was installed.  Note that the base directory name may vary with the version of Solr downloaded.  For example, with a shell in UNIX, Cygwin, or MacOS:


    /:$ ls solr*
    solr-4.10.2.zip
    /:$ unzip -q solr-4.10.2.zip
    /:$ cd solr-4.10.2/

To launch Solr, run `bin/solr start -e cloud -noprompt`:

    /solr-4.10.2:$ bin/solr start -e cloud -noprompt 
    Welcome to the SolrCloud example!


    Starting up 2 Solr nodes for your example SolrCloud cluster.
    ...

    Started Solr server on port 8983 (pid=8404). Happy searching!
    ...

    Started Solr server on port 7574 (pid=8549). Happy searching!
    ...

    SolrCloud example running, please visit http://localhost:8983/solr 

    /solr-4.10.2:$ 

Solr will now be running two "nodes", one on port 7574 and one on port 8983.  There are two collections created automatically, "collection1" and "gettingstarted".
These collections are different in a couple of ways: "collection1" is a single shard collection with two replicas and "gettingstarted" is a two shard
collection, each with two replicas.  The "Cloud" tab in the admin console diagrams it nicely:

<img alt="Solr Quick Start: SolrCloud diagram" class="float-right" src="/solr/assets/images/quickstart-solrcloud.png" />

You can see that the Solr is running by loading <http://localhost:8983/solr/> in your web browser. This is the main starting point for administering Solr.

***

<section class="orange full-width">
      <h1>That wasn't too hard!</h1>
      <p>
        You nailed step 1. Take a deep breath, relax a bit before round 2 below.
      </p>
      <div class="down-arrow"><a data-scroll href="#indexing-data"><i class="fa fa-angle-down fa-2x red"></i></a></div>
</section>
<br />

## Indexing Data

Your Solr server is up and running, but it doesn't contain any data.  The Solr install includes, literally, a `SimplePostTool`
in order to facilitate getting various types of documents into Solr easy from the start.  We'll be using this tool for the indexing examples below.

You'll need a command shell to run these examples, rooted in the Solr install directory; the shell from where you launched Solr works just fine.

Running the `SimplePostTool` can be made easier/cleaner to run by setting this in your environment:

    export CLASSPATH=dist/solr-core-4.10.2.jar

Or if you prefer, you can make every java command start with `java -classpath dist/solr-core-4.10.2.jar...`.  The examples provided below omit the -classpath argument and assume the CLASSPATH environment variable is set.


### Indexing a directory of "rich" files

Let's first index local "rich" files including HTML, PDF, Microsoft Office formats (such as MS Word), plain text and many other formats.  `SimplePostTool` features the ability to crawl a directory of files, optionally recursively even, sending the raw content of each file into Solr for extraction and indexing.   A Solr install includes a docs/ subdirectory, so that makes a convenient set of (mostly) HTML files built-in to start with.

    java -Dauto -Drecursive org.apache.solr.util.SimplePostTool docs/

Here's what it'll look like:

    /solr-4.10.2:$ java -Dauto -Drecursive org.apache.solr.util.SimplePostTool docs/
    SimplePostTool version 1.5
    Posting files to base url http://localhost:8983/solr/update..
    Entering auto mode. File endings considered are xml,json,csv,pdf,doc,docx,ppt,pptx,xls,xlsx,odt,odp,ods,ott,otp,ots,rtf,htm,html,txt,log
    Entering recursive mode, max depth=999, delay=0s
    Indexing directory docs (3 files, depth=0)
    POSTing file index.html (text/html)
    POSTing file SYSTEM_REQUIREMENTS.html (text/html)
    POSTing file tutorial.html (text/html)
    Indexing directory docs/changes (1 files, depth=1)
    POSTing file Changes.html (text/html)
    Indexing directory docs/solr-analysis-extras (8 files, depth=1)
    ...
    2945 files indexed.
    COMMITting Solr index changes to http://localhost:8983/solr/update..
    Time spent: 0:00:37.537

The command-line breaks down as follows:

   * `-Dauto -Drecursive`: Settings for directory recursing with automatic content type detection
   * `org.apache.solr.util.SimplePostTool`: Our easy to use friend in this tutorial
   * `docs/`: a relative path of the Solr install docs/ directory

You have now indexed thousands of documents into the "collection1" collection in Solr and committed these changes.
You can now search for "solr" by loading the "[Query](http://localhost:8983/solr/#/collection1/query)" tab in the Admin interface, and enter "solr" in the "q" text box. 

For something probably immediately useful to you would be to re-run the directory indexing command pointed, rather, to your own directory of documents.  For example, on a Mac instead of "docs/" try `~/Documents` or `~/Desktop`!   You may want to start from a clean, empty system again, rather than have your content in addition to the Solr docs/ directory; see below for how to get back to a clean starting point.

### Indexing Solr XML

Solr supports indexing structured content in a variety of incoming formats.  The historically predominant format for getting structured content into Solr has been [Solr XML](https://cwiki.apache.org/confluence/display/solr/Uploading+Data+with+Index+Handlers#UploadingDatawithIndexHandlers-XMLFormattedIndexUpdates).  Many Solr indexers have been coded to process domain content into Solr XML output, generally HTTP POSTed directly to Solr's /update endpoint.

Solr's install includes a handful of Solr XML formatted files with example data (mostly mocked tech product data).  

Using `SimplePostTool`, index the example XML files:

You can index all of the sample data, using the following command (assuming your command line shell supports the *.xml notation), this time making our command-line simpler by opening a terminal to the `example/exampledocs` directory and using post.jar.  Note: post.jar is a simple JAR file containing only the SimplePostTool used above.

    /solr-4.10.2:$ java org.apache.solr.util.SimplePostTool example/exampledocs/*.xml
    SimplePostTool version 1.5
    Posting files to base url http://localhost:8983/solr/update using content-type application/xml..
    POSTing file gb18030-example.xml
    POSTing file hd.xml
    POSTing file ipod_other.xml
    POSTing file ipod_video.xml
    POSTing file manufacturers.xml
    POSTing file mem.xml
    POSTing file money.xml
    POSTing file monitor.xml
    POSTing file monitor2.xml
    POSTing file mp500.xml
    POSTing file sd500.xml
    POSTing file solr.xml
    POSTing file utf8-example.xml
    POSTing file vidcard.xml
    14 files indexed.
    COMMITting Solr index changes to http://localhost:8983/solr/update..
    Time spent: 0:00:00.453

...and now you can search for all sorts of things using the default [Solr Query Syntax](https://cwiki.apache.org/confluence/display/solr/The+Standard+Query+Parser#TheStandardQueryParser-SpecifyingTermsfortheStandardQueryParser) (a superset of the Lucene query syntax)...


NOTE:
You can browse the documents indexed at <http://localhost:8983/solr/collection1/browse>.
The `/browse` UI allows getting a feel for how Solr's technical capabilities can be
worked with in a familiar, though a bit rough* and prototypical, interactive HTML view.  *The /browse view defaults to assuming the
"collection1" schema and data are a catch-all mix of structured XML, JSON, CSV example data, and unstructured rich documents.
Your own data may not look ideal at first, though the /browse templates are customizable.

### Indexing JSON

Solr supports indexing JSON, either arbitrary structured JSON or "Solr JSON" (which is similiar to Solr XML).

Solr includes a small sample Solr JSON file to illustrate this capability.  Again using `SimplePostTool`, index the sample JSON file:

    /solr-4.10.2:$ java -Dauto org.apache.solr.util.SimplePostTool example/exampledocs/books.json
    SimplePostTool version 1.5
    Posting files to base url http://localhost:8983/solr/update..
    Entering auto mode. File endings considered are xml,json,csv,...
    POSTing file books.json (application/json)
    1 files indexed.
    COMMITting Solr index changes to http://localhost:8983/solr/update..
    Time spent: 0:00:00.084

Because the SimplePostTool defaults to assuming files are in Solr XML format, the `-Dauto` switch is used to post JSON files so that it uses the appropriate content type.

To flatten and index arbitrary structured JSON, a topic beyond this quick start guide, check out [how to transform and flatten JSON](https://issues.apache.org/jira/browse/SOLR-6304).

### Indexing CSV (Comma/Column Separated Values)

A great conduit of data into Solr is via CSV, especially when the documents are homogonenous and generally all have the same set of fields.  CSV can be conveniently exported from a spreadsheet such as Excel, or exported from databases such as MySQL.  When getting started with Solr, it can often be easiest to get your structured data into CSV format and then index that into Solr rather than a more sophisticated single step operation.

Using SimplePostTool and the included example CSV data file, index it:

    /solr-4.10.2:$ java -Dauto org.apache.solr.util.SimplePostTool example/exampledocs/books.csv
    SimplePostTool version 1.5
    Posting files to base url http://localhost:8983/solr/update..
    Entering auto mode. File endings considered are xml,json,csv,...
    POSTing file books.csv (text/csv)
    1 files indexed.
    COMMITting Solr index changes to http://localhost:8983/solr/update..
    Time spent: 0:00:00.084

### Other indexing techniques

* Import records from a database using the [Data Import Handler (DIH)](https://cwiki.apache.org/confluence/display/solr/Uploading+Structured+Data+Store+Data+with+the+Data+Import+Handler).
    
* Use [SolrJ](https://cwiki.apache.org/confluence/display/solr/Using+SolrJ) for Java or other Solr clients to programatically create documents to send to Solr.

***

## Updating Data

You may notice that even if you index content in this guide more than once, it does not duplicate the results found. This is because the example `schema.xml` specifies a "`uniqueKey`" field called "id". Whenever you POST commands to Solr to add a document with the same value for the uniqueKey as an existing document, it automatically replaces it for you. You can see that that has happened by looking at the values for numDocs and maxDoc in the "CORE"/searcher section of the statistics page...

<http://localhost:8983/solr/#/collection1/plugins/core?entry=searcher>

numDocs represents the number of searchable documents in the index (and will be larger than the number of XML, JSON, or CSV files since some files contained more than one document).  The maxDoc value may be larger as the maxDoc count includes logically deleted documents that have not yet been removed from the index. You can re-post the sample files over and over again as much as you want and numDocs will never increase, because the new documents will constantly be replacing the old.

Go ahead and edit any of the existing example data files, change some of the data, and re-run the SimplePostTool command.  You'll see your changes reflected in subsequent searches.

## Deleting Data

You can delete data by POSTing a delete command to the update URL and specifying the value of the document's unique key field, or a query that matches multiple documents (be careful with that one!). Since these commands are smaller, we specify them right on the command line rather than reference a JSON or XML file.

Execute the following command to delete a specific document

    java -Ddata=args -jar post.jar "<delete><id>SP2514N</id></delete>"

***

<section class="orange full-width">
      <h1>Way to go!!!</h1>
      <p>
        Round 2, check. Now get up and do some jumping jacks. Heck, go for a run and leave your house, you deserve it.
      </p>
      <div class="down-arrow"><a data-scroll href="#wrapping-up"><i class="fa fa-angle-down fa-2x red"></i></a></div>
</section>
<br />

## Wrapping up

If you've run the full set of commands in this quick start guide you have done the following:

* Launched Solr into SolrCloud mode, two nodes, two collections including shards and replicas
* Indexed a directory of rich text files
* Indexed Solr XML files
* Indexed Solr JSON files
* Indexed CSV content
* Opened the admin console, used its query interface to get JSON formatted results
* Opened the /browse interface to explore Solr's features in a more friendly and familiar interface

Nice work!   The script (see below) to run all of these items took under one and half minutes! (your run time may vary, depending on your computers power and resources available)

Here's a full Unix script for convenient copying and pasting in order to run all of the commands for this quick start guide:

    export CLASSPATH=dist/solr-core-4.10.2.jar
    date ;
    bin/solr start -e cloud -noprompt ; 
       open http://localhost:8983/solr ;
       java -Dauto -Drecursive org.apache.solr.util.SimplePostTool docs/ ; 
       open http://localhost:8983/solr/collection1/browse ;
       java org.apache.solr.util.SimplePostTool example/exampledocs/*.xml ;
       java -Dauto org.apache.solr.util.SimplePostTool example/exampledocs/books.json ;
       java -Ddata=args org.apache.solr.util.SimplePostTool "<delete><id>SP2514N</id></delete>" ;
    date ;


### Cleanup:

As you work through this guide, you may want to stop Solr and reset the environment back to the starting point.  The following command line will stop Solr and remove the directories for each of the two nodes that the start script created:

   bin/solr stop -all ; rm -Rf node1/ node2/ 






