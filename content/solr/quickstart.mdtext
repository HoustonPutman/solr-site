Title: Quick Start

<ul class="breadcrumbs">
  <li><a href="/solr">Home</a></li>
  <li><a href="/solr/resources.html">Resources</a></li>
</ul>

# Solr Quick Start

***

## Overview

<!--
  TODO: Where to mention (or not?) the Solr version number this is for?   It's intentionally embedded in the examples below, at least.

  4.10.2 was used to write this quick start guide
-->

This document covers getting Solr up and running, ingesting a variety of data sources into multiple collections, and getting a feel
for the Solr administrative and search interfaces.

***

## Requirements

<!-- TODO: Replace this section with an include?  Or at least link to a common system requirements page rather than duplicating here. -->

To follow along with this tutorial, you will need...

1. Java 1.7 or greater. Some places you can get it are from Oracle or Open JDK.
    * Running java -version at the command line should indicate a version number starting with 1.7.
    * Gnu's GCJ is not supported and does not work with Solr.
2. A Solr release.
    
***

## Getting Started

Please run the browser showing this tutorial and the Solr server on the same machine so tutorial links will correctly point to your Solr server.

Begin by unzipping the Solr release and changing your working directory to be the "example" directory. (Note that the base directory name may vary with the version of Solr downloaded.) For example, with a shell in UNIX, Cygwin, or MacOS:


    /:$ ls solr*
    solr-4.10.2.zip
    /:$ unzip -q solr-4.10.2.zip
    /:$ cd solr-4.10.2/

To launch Solr, run `bin/solr start -e cloud -noprompt`:

    /solr-4.10.2:$ bin/solr start -e cloud -noprompt 
    Welcome to the SolrCloud example!


    Starting up 2 Solr nodes for your example SolrCloud cluster.
    ...

    Started Solr server on port 8983 (pid=8404). Happy searching!
    ...

    Started Solr server on port 7574 (pid=8549). Happy searching!
    ...

    SolrCloud example running, please visit http://localhost:8983/solr 

    /solr-4.10.2:$ 

Solr will now be running two "nodes", one on port 7574 and one on port 8983.  There are two collections created automatically, "collection1" and "gettingstarted".
These collections are different in a couple of ways: "collection1" is a single shard collection with two replicas and "gettingstarted" is a two shard
collection, each with two replicas.  The "Cloud" tab in the admin console diagrams it nicely:

<img alt="Solr Quick Start: SolrCloud diagram" class="float-right" src="/solr/assets/images/quickstart-solrcloud.png" />

You can see that the Solr is running by loading <http://localhost:8983/solr/> in your web browser. This is the main starting point for administering Solr.

***

<section class="orange">
      <h1>That wasn't too hard!</h1>
      <p>
        You nailed step 1. Take a deep breath, relax a bit before round 2 below.
      </p>
      <div class="down-arrow"><a data-scroll href="#indexing-data"><i class="fa fa-angle-down fa-2x red"></i></a></div>
</section>

## Indexing Data

Your Solr server is up and running, but it doesn't contain any data.  The Solr install includes, literally, a `SimplePostTool`
in order to facilitate getting various types of documents into Solr easy from the start.  We'll be using this tool for the indexing examples below.

You'll need a command shell to run these examples, rooted in the Solr install directory; the shell from where you launched Solr works just fine.

Running the `SimplePostTool` can be made easier/cleaner to run by setting this in your environment:

    export CLASSPATH=example/solr-webapp/webapp/WEB-INF/lib/solr-core-4.10.2.jar

Or if you prefer, you can make every java command start with `java -classpath example/solr-webapp/webapp/WEB-INF/lib/solr-core-4.10.2.jar...`.
The examples provided below omit the -classpath argument and assume the CLASSPATH environment variable is set.


### Indexing a directory of "rich" files

Let's first index local "rich" files (HTML, PDF, text, and many other supported formats).  `SimplePostTool` features the ability to crawl a directory
of files, optionally recursively even, sending the raw content of each file into Solr for extraction and indexing.   A Solr install includes a docs/
subdirectory, so that makes a convenient set of (mostly) HTML files built-in to start with.

    java -Ddata=files -Dauto -Drecursive org.apache.solr.util.SimplePostTool docs/

Here's what it'll look like:

    /solr-4.10.2:$ java -Ddata=files -Dauto -Drecursive org.apache.solr.util.SimplePostTool docs/
    SimplePostTool version 1.5
    Posting files to base url http://localhost:8983/solr/update..
    Entering auto mode. File endings considered are xml,json,csv,pdf,doc,docx,ppt,pptx,xls,xlsx,odt,odp,ods,ott,otp,ots,rtf,htm,html,txt,log
    Entering recursive mode, max depth=999, delay=0s
    Indexing directory docs (3 files, depth=0)
    POSTing file index.html (text/html)
    POSTing file SYSTEM_REQUIREMENTS.html (text/html)
    POSTing file tutorial.html (text/html)
    Indexing directory docs/changes (1 files, depth=1)
    POSTing file Changes.html (text/html)
    Indexing directory docs/solr-analysis-extras (8 files, depth=1)
    ...
    2945 files indexed.
    COMMITting Solr index changes to http://localhost:8983/solr/update..
    Time spent: 0:00:37.537

The command-line breaks down as follows:

   * `-Ddata=files -Dauto -Drecursive`: Settings for directory recursing with automatic content type detection
   * `org.apache.solr.util.SimplePostTool`: Our easy to use friend in this tutorial
   * `docs/`: a relative path of the Solr install docs/ directory


You have now indexed thousands of documents into the "collection1" collection in Solr and committed these changes.
You can now search for "solr" by loading the "[Query]()" tab in the Admin interface, and entering "solr" in the "q" text box. Clicking the "Execute Query" button should display the following URL containing one result.

   <http://localhost:8983/solr/collection1/select?q=solr&wt=xml>

NOTE: /browse call out (?)
You can browse the documents indexed at <http://localhost:8983/solr/collection1/browse>.
The `/browse` UI allows getting a feel for how Solr's technical capabilities can be
worked with in a familiar, though a bit rough* and prototypical, interactive HTML view.  *The /browse views default to assuming the
"collection1" schema and data are a catch-all mix of structured XML, JSON, CSV example data, and unstructured rich documents.
Your own data may not look ideal at first, though the /browse templates are malleable as desired.

For something probably immediately useful to you would be to re-run the directory indexing command pointed, rather, to your own directory of documents.  For example, on a Mac instead of "docs/" try `~/Documents` or `~/Desktop`!   You may want to start from a clean empty system again, rather than have your content in addition to the Solr docs/ directory.

### Indexing Solr XML

Solr supports indexing structured content in a variety of incoming formats.  The historically predominant format for getting structured content into Solr has been [Solr XML](link).  Many Solr indexers have been coded to process domain content into Solr XML output, generally HTTP POSTed directly to Solr's /update endpoint.

Solr's install includes a handful of Solr XML formatted files with example data (mostly mocked tech product data).  

Using `SimplePostTool`, index the example XML files:

You can index all of the sample data, using the following command (assuming your command line shell supports the *.xml notation), this time making our command-line simpler by opening a terminal to the `example/exampledocs` directory and using post.jar.  Note: post.jar is a simple JAR file containing only the SimplePostTool used above.

    /solr-4.10.2:$ java org.apache.solr.util.SimplePostTool example/exampledocs/*.xml
    SimplePostTool version 1.5
    Posting files to base url http://localhost:8983/solr/update using content-type application/xml..
    POSTing file gb18030-example.xml
    POSTing file hd.xml
    POSTing file ipod_other.xml
    POSTing file ipod_video.xml
    POSTing file manufacturers.xml
    POSTing file mem.xml
    POSTing file money.xml
    POSTing file monitor.xml
    POSTing file monitor2.xml
    POSTing file mp500.xml
    POSTing file sd500.xml
    POSTing file solr.xml
    POSTing file utf8-example.xml
    POSTing file vidcard.xml
    14 files indexed.
    COMMITting Solr index changes to http://localhost:8983/solr/update..
    Time spent: 0:00:00.453

...and now you can search for all sorts of things using the default [Solr Query Syntax]() (a superset of the Lucene query syntax)...

* [video]()
* [name:video]()
* [+video +price:[* TO 400]]()

There are many other different ways to import your data into Solr... one can

* Import records from a database using the [Data Import Handler (DIH)]().
    
* [Load a CSV file]() (comma separated values), including those exported by Excel or MySQL.

* [POST JSON documents]()

* Index binary documents such as Word and PDF with [Solr Cell]() (ExtractingRequestHandler).

* Use [SolrJ]() for Java or other Solr clients to programatically create documents to send to Solr.

***

## Updating Data

You may have noticed that even though the file `solr.xml` has now been POSTed to the server twice, you still only get 1 result when searching for "solr". This is because the example `schema.xml` specifies a "`uniqueKey`" field called "id". Whenever you POST commands to Solr to add a document with the same value for the uniqueKey as an existing document, it automatically replaces it for you. You can see that that has happened by looking at the values for numDocs and maxDoc in the "CORE"/searcher section of the statistics page...

<http://localhost:8983/solr/#/collection1/plugins/core?entry=searcher>

numDocs represents the number of searchable documents in the index (and will be larger than the number of XML files since some files contained more than one <doc>). maxDoc may be larger as the maxDoc count includes logically deleted documents that have not yet been removed from the index. You can re-post the sample XML files over and over again as much as you want and numDocs will never increase, because the new documents will constantly be replacing the old.

Go ahead and edit the existing XML files to change some of the data, and re-run the java -jar post.jar command, you'll see your changes reflected in subsequent searches.

## Deleting Data

You can delete data by POSTing a delete command to the update URL and specifying the value of the document's unique key field, or a query that matches multiple documents (be careful with that one!). Since these commands are smaller, we will specify them right on the command line rather than reference an XML file.

Execute the following command to delete a specific document

    java -Ddata=args -Dcommit=false -jar post.jar "<delete><id>SP2514N</id></delete>"

***

<section class="orange">
      <h1>Way to go!!!</h1>
      <p>
        Round 2, check. Now get up and do some jumping jacks. Heck, go for a run and leave your house, you deserve it.
      </p>
      <div class="down-arrow"><a data-scroll href="#indexing-data"><i class="fa fa-angle-down fa-2x red"></i></a></div>
</section>


Cleanup:
   bin/solr stop -all ; rm -Rf node1/ node2/ 


Full script and then console output:

export CLASSPATH=dist/solr-core-4.10.2.jar
date ;
bin/solr start -e cloud -noprompt ; 
   open http://localhost:8983/solr ;
   java -Ddata=files -Dauto -Drecursive org.apache.solr.util.SimplePostTool docs/ ; 
   java org.apache.solr.util.SimplePostTool example/exampledocs/*.xml ;
   open http://localhost:8983/solr/collection1/browse ;
date ;







